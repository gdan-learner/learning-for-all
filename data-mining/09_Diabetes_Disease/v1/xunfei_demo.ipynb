{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 糖尿病遗传风险检测挑战赛\n",
    "\n",
    "## **赛题介绍**\n",
    "\n",
    "截至2022年，中国糖尿病患者近1.3亿。中国糖尿病患病原因受生活方式、老龄化、城市化、家族遗传等多种因素影响。同时，糖尿病患者趋向年轻化。\n",
    "\n",
    "糖尿病可导致心血管、肾脏、脑血管并发症的发生。因此，准确诊断出患有糖尿病个体具有非常重要的临床意义。糖尿病早期遗传风险预测将有助于预防糖尿病的发生。\n",
    "\n",
    "**赛事地址**：https://challenge.xfyun.cn/topic/info?type=diabetes&ch=ds22-dw-zmt01\n",
    "\n",
    "## **赛题任务**\n",
    "\n",
    "在这次比赛中，您需要通过**训练数据集**构建**糖尿病遗传风险预测模型**，然后预测出**测试数据集**中个体是否患有糖尿病，和我们一起帮助糖尿病患者解决这“甜蜜的烦恼”。\n",
    "\n",
    "## **赛题数据**\n",
    "\n",
    "赛题数据由训练集和测试集组成，具体情况如下：\n",
    "\n",
    "- 训练集：共有5070条数据，用于构建您的预测模型\n",
    "- 测试集：共有1000条数据，用于验证预测模型的性能。\n",
    "\n",
    "其中训练集数据包含有9个字段：性别、出生年份、体重指数、糖尿病家族史、舒张压、口服耐糖量测试、胰岛素释放实验、肱三头肌皮褶厚度、患有糖尿病标识（数据标签）。\n",
    "\n",
    "## **评分标准**\n",
    "\n",
    "采用二分类任务中的F1-score指标进行评价，F1-score越大说明预测模型性能越好，F1-score的定义如下：\n",
    "\n",
    "![图片](https://oss.linklearner.com/competition/tangniaobing/1002.png)\n",
    "\n",
    "其中：\n",
    "\n",
    "![图片](https://oss.linklearner.com/competition/tangniaobing/1003.png)\n",
    "\n",
    "![图片](https://oss.linklearner.com/competition/tangniaobing/1004.png)\n",
    "\n",
    "\n",
    "\n",
    "> Tips: 根据题意，糖尿病遗传风险检测挑战赛中会提供2个数据集，分别是训练数据集和测试数据集，其中训练数据集有特征数据和数据标签（患者是否得糖尿病），测试数据集只有特征数据，我们需要根据**糖尿病遗传风险预测模型**，比赛方通过测试数据集来评估模型的预测准确性，模型预测的准确性越高越好。\n",
    "\n",
    "> Ref：\n",
    ">\n",
    "> - [知乎：二分类问题常见的评价指标](https://zhuanlan.zhihu.com/p/55324860)\n",
    "\n",
    "## **赛题Baseline**\n",
    "\n",
    "> Tips:  在本次比赛中，我们将提供python代码用于比赛数据的分析与模型构建，如果你还不熟悉赛题中的相关代码与原理，可以参考相关学习资料或在Datawhale交流群中来解决你遇到的问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **安装相关第三方库**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **导入第三方库**\n",
    "\n",
    "> Tips: 在本baseline中，我们通过pandas对数据进行处理，通过lightgbm算法来构建**糖尿病遗传风险预测模型**\n",
    ">\n",
    "> Ref:\n",
    ">\n",
    "> - [CSDN：pandas用法-全网最详细教程](https://blog.csdn.net/yiyele/article/details/80605909)\n",
    "> - [Datawhale：Joyful-Pandas](http://joyfulpandas.datawhale.club/Home.html)\n",
    "> - [Datawhale：我的Pandas学习经历及动手实践](https://mp.weixin.qq.com/s/A232A6OLxrlsZUx0VGv3Ow)\n",
    "> - [知乎：深入理解LightGBM](https://zhuanlan.zhihu.com/p/99069186)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **数据预处理**\n",
    "\n",
    "> Tips: 在本环节中，我们通常需要检测数据的质量，包括重复值、异常值、缺失值、数据分布和数据特征等，通过训练数据的预处理，我们能得到更高质量的训练数据，这有助于构建更加准确的预测模型。\n",
    ">\n",
    "> 在本baseline中，我们发现`舒张压`特征中存在缺失值，我们采用了填充缺失值的方法进行处理，当然也有其他的处理方法，如果感兴趣可以尝试。\n",
    ">\n",
    "> Ref:\n",
    ">\n",
    "> - [知乎：机器学习（三）：数据预处理--数据预处理的基本方法](https://zhuanlan.zhihu.com/p/100442371)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=pd.read_csv('data\\比赛训练集.csv',encoding='gbk')\n",
    "data2=pd.read_csv('data\\比赛测试集.csv',encoding='gbk')\n",
    "\n",
    "#label标记为-1\n",
    "data2['患有糖尿病标识']=-1\n",
    "#训练集和测试机合并\n",
    "data=pd.concat([data1,data2],axis=0,ignore_index=True)\n",
    "#将舒张压特征中的缺失值填充为-1\n",
    "data['舒张压']=data['舒张压'].fillna(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征工程\n",
    "\n",
    ">Tips：在本环节中，我们需要对数据进行特征的构造，目的是最大限度地从原始数据中提取特征以供算法和模型使用，这有助于构建更加准确的预测模型。\n",
    ">\n",
    ">Ref:\n",
    ">\n",
    ">- [CSDN：什么是特征工程？如何进行特征工程？](https://blog.csdn.net/qq_39521554/article/details/78877505)\n",
    ">- [Datawhale：用机器学习神器sklearn做特征工程！](https://mp.weixin.qq.com/s/AwjEfC2wLhUF9Ecgt0kocw)\n",
    ">- [Datawhale：特征工程在实际业务中的应用！](https://mp.weixin.qq.com/s/63p5UFrf9a2Sfwz9H1XpgQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#特征工程\n",
    "\"\"\"\n",
    "将出生年份换算成年龄\n",
    "\"\"\"\n",
    "data['出生年份']=2022-data['出生年份']  #换成年龄\n",
    "\"\"\"\n",
    "人体的成人体重指数正常值是在18.5-24之间\n",
    "低于18.5是体重指数过轻\n",
    "在24-27之间是体重超重\n",
    "27以上考虑是肥胖\n",
    "高于32了就是非常的肥胖。\n",
    "\"\"\"\n",
    "def BMI(a):\n",
    "   if a<18.5:\n",
    "       return 0\n",
    "   elif 18.5<=a<=24:\n",
    "       return 1\n",
    "   elif 24<a<=27:\n",
    "       return 2\n",
    "   elif 27<a<=32:\n",
    "       return 3\n",
    "   else:\n",
    "       return 4\n",
    "\n",
    "data['BMI']=data['体重指数'].apply(BMI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#糖尿病家族史\n",
    "\"\"\"\n",
    "无记录\n",
    "叔叔或者姑姑有一方患有糖尿病/叔叔或姑姑有一方患有糖尿病\n",
    "父母有一方患有糖尿病\n",
    "\"\"\"\n",
    "def FHOD(a):\n",
    "   if a=='无记录':\n",
    "       return 0\n",
    "   elif a=='叔叔或者姑姑有一方患有糖尿病' or a=='叔叔或姑姑有一方患有糖尿病':\n",
    "       return 1\n",
    "   else:\n",
    "       return 2\n",
    "\n",
    "data['糖尿病家族史']=data['糖尿病家族史'].apply(FHOD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "舒张压范围为60-90\n",
    "\"\"\"\n",
    "def DBP(a):\n",
    "   if a<60:\n",
    "       return 0\n",
    "   elif 60<=a<=90:\n",
    "       return 1\n",
    "   elif a>90:\n",
    "       return 2\n",
    "   else:\n",
    "       return a\n",
    "data['DBP']=data['舒张压'].apply(DBP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------\n",
    "#将处理好的特征工程分为训练集和测试集，其中训练集是用来训练模型，测试集用来评估模型准确度\n",
    "#其中编号和患者是否得糖尿病没有任何联系，属于无关特征予以删除\n",
    "train=data[data['患有糖尿病标识'] !=-1]\n",
    "test=data[data['患有糖尿病标识'] ==-1]\n",
    "train_label=train['患有糖尿病标识']\n",
    "train=train.drop(['编号','患有糖尿病标识'],axis=1)\n",
    "test=test.drop(['编号','患有糖尿病标识'],axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建模型\n",
    "\n",
    "> Tips：在本环节中，我们需要对训练集进行训练从而构建相应的模型，在本baseline中我们使用了Lightgbm算法进行数据训练，当然你也可以使用其他的机器学习算法/深度学习算法，甚至你可以将不同算法预测的结果进行综合，反正最后的目的是获得更高的预测准确度，向着这个目标出发~\n",
    ">\n",
    "> 在本节中，我们将训练数据使用5折交叉验证训练的方法进行训练，这是一个不错的提升模型预测准确度的方法\n",
    ">\n",
    "> Ref:\n",
    ">\n",
    "> - [Datawhale：数据竞赛Baseline & Topline分享](https://github.com/datawhalechina/competition-baseline)\n",
    "> - [Datawhale：数据挖掘与机器学习](https://github.com/datawhalechina/team-learning-data-mining)\n",
    "> - [Datawhale：西瓜书代码实战](https://github.com/datawhalechina/machine-learning-toy-code)\n",
    "> - [CSDN：Kaggle上分技巧——单模K折交叉验证训练+多模型融合](https://blog.csdn.net/fengjiandaxia/article/details/123096182)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用Lightgbm方法训练数据集，使用5折交叉验证的方法获得5个测试集预测结果\n",
    "from sklearn.model_selection import KFold\n",
    "def select_by_lgb(train_data,train_label,test_data,random_state=2022,n_splits=2,metric='auc',num_round=10000,early_stopping_rounds=100):\n",
    "   kfold = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "   fold=0\n",
    "   result=[]\n",
    "   for train_idx, val_idx in kfold.split(train_data):\n",
    "       random_state+=1\n",
    "       train_x = train_data.loc[train_idx]\n",
    "       train_y = train_label.loc[train_idx]\n",
    "       test_x = train_data.loc[val_idx]\n",
    "       test_y = train_label.loc[val_idx]\n",
    "       clf=lightgbm\n",
    "       train_matrix=clf.Dataset(train_x,label=train_y)\n",
    "       test_matrix=clf.Dataset(test_x,label=test_y)\n",
    "       params={\n",
    "               'boosting_type': 'gbdt',\n",
    "               'objective': 'binary',\n",
    "               'learning_rate': 0.1,\n",
    "               'metric': metric,\n",
    "               'seed': 2020,\n",
    "               'nthread':-1 }\n",
    "       model=clf.train(params,train_matrix,num_round,valid_sets=test_matrix,early_stopping_rounds=early_stopping_rounds)\n",
    "       pre_y=model.predict(test_data)\n",
    "       result.append(pre_y)\n",
    "       fold+=1\n",
    "   return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\96212\\anaconda3\\envs\\ML\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 983, number of negative: 1552\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000487 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1019\n",
      "[LightGBM] [Info] Number of data points in the train set: 2535, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.387771 -> initscore=-0.456691\n",
      "[LightGBM] [Info] Start training from score -0.456691\n",
      "[1]\tvalid_0's auc: 0.983183\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's auc: 0.983933\n",
      "[3]\tvalid_0's auc: 0.983622\n",
      "[4]\tvalid_0's auc: 0.983787\n",
      "[5]\tvalid_0's auc: 0.984428\n",
      "[6]\tvalid_0's auc: 0.984482\n",
      "[7]\tvalid_0's auc: 0.984779\n",
      "[8]\tvalid_0's auc: 0.986113\n",
      "[9]\tvalid_0's auc: 0.987298\n",
      "[10]\tvalid_0's auc: 0.987335\n",
      "[11]\tvalid_0's auc: 0.987371\n",
      "[12]\tvalid_0's auc: 0.987752\n",
      "[13]\tvalid_0's auc: 0.987772\n",
      "[14]\tvalid_0's auc: 0.98771\n",
      "[15]\tvalid_0's auc: 0.987735\n",
      "[16]\tvalid_0's auc: 0.987783\n",
      "[17]\tvalid_0's auc: 0.987813\n",
      "[18]\tvalid_0's auc: 0.988125\n",
      "[19]\tvalid_0's auc: 0.9882\n",
      "[20]\tvalid_0's auc: 0.988213\n",
      "[21]\tvalid_0's auc: 0.987705\n",
      "[22]\tvalid_0's auc: 0.987732\n",
      "[23]\tvalid_0's auc: 0.987747\n",
      "[24]\tvalid_0's auc: 0.987756\n",
      "[25]\tvalid_0's auc: 0.987837\n",
      "[26]\tvalid_0's auc: 0.987705\n",
      "[27]\tvalid_0's auc: 0.988196\n",
      "[28]\tvalid_0's auc: 0.988687\n",
      "[29]\tvalid_0's auc: 0.988666\n",
      "[30]\tvalid_0's auc: 0.988461\n",
      "[31]\tvalid_0's auc: 0.988434\n",
      "[32]\tvalid_0's auc: 0.988793\n",
      "[33]\tvalid_0's auc: 0.988686\n",
      "[34]\tvalid_0's auc: 0.988735\n",
      "[35]\tvalid_0's auc: 0.988954\n",
      "[36]\tvalid_0's auc: 0.989256\n",
      "[37]\tvalid_0's auc: 0.989047\n",
      "[38]\tvalid_0's auc: 0.989064\n",
      "[39]\tvalid_0's auc: 0.989596\n",
      "[40]\tvalid_0's auc: 0.989605\n",
      "[41]\tvalid_0's auc: 0.990017\n",
      "[42]\tvalid_0's auc: 0.990201\n",
      "[43]\tvalid_0's auc: 0.99017\n",
      "[44]\tvalid_0's auc: 0.990218\n",
      "[45]\tvalid_0's auc: 0.990264\n",
      "[46]\tvalid_0's auc: 0.990223\n",
      "[47]\tvalid_0's auc: 0.990132\n",
      "[48]\tvalid_0's auc: 0.990158\n",
      "[49]\tvalid_0's auc: 0.990196\n",
      "[50]\tvalid_0's auc: 0.990093\n",
      "[51]\tvalid_0's auc: 0.99024\n",
      "[52]\tvalid_0's auc: 0.990208\n",
      "[53]\tvalid_0's auc: 0.989998\n",
      "[54]\tvalid_0's auc: 0.990056\n",
      "[55]\tvalid_0's auc: 0.989991\n",
      "[56]\tvalid_0's auc: 0.989953\n",
      "[57]\tvalid_0's auc: 0.989887\n",
      "[58]\tvalid_0's auc: 0.989742\n",
      "[59]\tvalid_0's auc: 0.989682\n",
      "[60]\tvalid_0's auc: 0.989646\n",
      "[61]\tvalid_0's auc: 0.989456\n",
      "[62]\tvalid_0's auc: 0.989332\n",
      "[63]\tvalid_0's auc: 0.989436\n",
      "[64]\tvalid_0's auc: 0.989681\n",
      "[65]\tvalid_0's auc: 0.989742\n",
      "[66]\tvalid_0's auc: 0.989776\n",
      "[67]\tvalid_0's auc: 0.989736\n",
      "[68]\tvalid_0's auc: 0.989745\n",
      "[69]\tvalid_0's auc: 0.989817\n",
      "[70]\tvalid_0's auc: 0.989697\n",
      "[71]\tvalid_0's auc: 0.989632\n",
      "[72]\tvalid_0's auc: 0.98942\n",
      "[73]\tvalid_0's auc: 0.989549\n",
      "[74]\tvalid_0's auc: 0.989531\n",
      "[75]\tvalid_0's auc: 0.989499\n",
      "[76]\tvalid_0's auc: 0.989458\n",
      "[77]\tvalid_0's auc: 0.989526\n",
      "[78]\tvalid_0's auc: 0.989514\n",
      "[79]\tvalid_0's auc: 0.989403\n",
      "[80]\tvalid_0's auc: 0.989277\n",
      "[81]\tvalid_0's auc: 0.989412\n",
      "[82]\tvalid_0's auc: 0.989318\n",
      "[83]\tvalid_0's auc: 0.989393\n",
      "[84]\tvalid_0's auc: 0.989291\n",
      "[85]\tvalid_0's auc: 0.989303\n",
      "[86]\tvalid_0's auc: 0.989255\n",
      "[87]\tvalid_0's auc: 0.989238\n",
      "[88]\tvalid_0's auc: 0.9892\n",
      "[89]\tvalid_0's auc: 0.989158\n",
      "[90]\tvalid_0's auc: 0.98903\n",
      "[91]\tvalid_0's auc: 0.988788\n",
      "[92]\tvalid_0's auc: 0.988885\n",
      "[93]\tvalid_0's auc: 0.988855\n",
      "[94]\tvalid_0's auc: 0.988721\n",
      "[95]\tvalid_0's auc: 0.988782\n",
      "[96]\tvalid_0's auc: 0.9888\n",
      "[97]\tvalid_0's auc: 0.988723\n",
      "[98]\tvalid_0's auc: 0.988639\n",
      "[99]\tvalid_0's auc: 0.988655\n",
      "[100]\tvalid_0's auc: 0.98857\n",
      "[101]\tvalid_0's auc: 0.988548\n",
      "[102]\tvalid_0's auc: 0.988475\n",
      "[103]\tvalid_0's auc: 0.988483\n",
      "[104]\tvalid_0's auc: 0.988316\n",
      "[105]\tvalid_0's auc: 0.988337\n",
      "[106]\tvalid_0's auc: 0.988373\n",
      "[107]\tvalid_0's auc: 0.988401\n",
      "[108]\tvalid_0's auc: 0.988312\n",
      "[109]\tvalid_0's auc: 0.988355\n",
      "[110]\tvalid_0's auc: 0.988407\n",
      "[111]\tvalid_0's auc: 0.988406\n",
      "[112]\tvalid_0's auc: 0.988495\n",
      "[113]\tvalid_0's auc: 0.988504\n",
      "[114]\tvalid_0's auc: 0.988408\n",
      "[115]\tvalid_0's auc: 0.988355\n",
      "[116]\tvalid_0's auc: 0.988329\n",
      "[117]\tvalid_0's auc: 0.988311\n",
      "[118]\tvalid_0's auc: 0.988263\n",
      "[119]\tvalid_0's auc: 0.98829\n",
      "[120]\tvalid_0's auc: 0.98827\n",
      "[121]\tvalid_0's auc: 0.988288\n",
      "[122]\tvalid_0's auc: 0.988335\n",
      "[123]\tvalid_0's auc: 0.988461\n",
      "[124]\tvalid_0's auc: 0.98832\n",
      "[125]\tvalid_0's auc: 0.988369\n",
      "[126]\tvalid_0's auc: 0.988378\n",
      "[127]\tvalid_0's auc: 0.988366\n",
      "[128]\tvalid_0's auc: 0.988418\n",
      "[129]\tvalid_0's auc: 0.98832\n",
      "[130]\tvalid_0's auc: 0.988252\n",
      "[131]\tvalid_0's auc: 0.988163\n",
      "[132]\tvalid_0's auc: 0.988202\n",
      "[133]\tvalid_0's auc: 0.988146\n",
      "[134]\tvalid_0's auc: 0.988078\n",
      "[135]\tvalid_0's auc: 0.988099\n",
      "[136]\tvalid_0's auc: 0.98815\n",
      "[137]\tvalid_0's auc: 0.988245\n",
      "[138]\tvalid_0's auc: 0.98829\n",
      "[139]\tvalid_0's auc: 0.988272\n",
      "[140]\tvalid_0's auc: 0.988272\n",
      "[141]\tvalid_0's auc: 0.988324\n",
      "[142]\tvalid_0's auc: 0.988226\n",
      "[143]\tvalid_0's auc: 0.988221\n",
      "[144]\tvalid_0's auc: 0.988205\n",
      "[145]\tvalid_0's auc: 0.988196\n",
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's auc: 0.990264\n",
      "[LightGBM] [Info] Number of positive: 953, number of negative: 1582\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000235 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1007\n",
      "[LightGBM] [Info] Number of data points in the train set: 2535, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.375937 -> initscore=-0.506830\n",
      "[LightGBM] [Info] Start training from score -0.506830\n",
      "[1]\tvalid_0's auc: 0.985415\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's auc: 0.982248\n",
      "[3]\tvalid_0's auc: 0.982273\n",
      "[4]\tvalid_0's auc: 0.982056\n",
      "[5]\tvalid_0's auc: 0.983674\n",
      "[6]\tvalid_0's auc: 0.985037\n",
      "[7]\tvalid_0's auc: 0.985328\n",
      "[8]\tvalid_0's auc: 0.987014\n",
      "[9]\tvalid_0's auc: 0.987033\n",
      "[10]\tvalid_0's auc: 0.987879\n",
      "[11]\tvalid_0's auc: 0.987785\n",
      "[12]\tvalid_0's auc: 0.988719\n",
      "[13]\tvalid_0's auc: 0.988725\n",
      "[14]\tvalid_0's auc: 0.98887\n",
      "[15]\tvalid_0's auc: 0.988806\n",
      "[16]\tvalid_0's auc: 0.988835\n",
      "[17]\tvalid_0's auc: 0.988623\n",
      "[18]\tvalid_0's auc: 0.988591\n",
      "[19]\tvalid_0's auc: 0.98867\n",
      "[20]\tvalid_0's auc: 0.988503\n",
      "[21]\tvalid_0's auc: 0.988629\n",
      "[22]\tvalid_0's auc: 0.988561\n",
      "[23]\tvalid_0's auc: 0.988529\n",
      "[24]\tvalid_0's auc: 0.989093\n",
      "[25]\tvalid_0's auc: 0.989604\n",
      "[26]\tvalid_0's auc: 0.989598\n",
      "[27]\tvalid_0's auc: 0.989703\n",
      "[28]\tvalid_0's auc: 0.989055\n",
      "[29]\tvalid_0's auc: 0.987442\n",
      "[30]\tvalid_0's auc: 0.987469\n",
      "[31]\tvalid_0's auc: 0.987254\n",
      "[32]\tvalid_0's auc: 0.987329\n",
      "[33]\tvalid_0's auc: 0.988823\n",
      "[34]\tvalid_0's auc: 0.989054\n",
      "[35]\tvalid_0's auc: 0.988833\n",
      "[36]\tvalid_0's auc: 0.9888\n",
      "[37]\tvalid_0's auc: 0.988673\n",
      "[38]\tvalid_0's auc: 0.988745\n",
      "[39]\tvalid_0's auc: 0.988678\n",
      "[40]\tvalid_0's auc: 0.988762\n",
      "[41]\tvalid_0's auc: 0.988862\n",
      "[42]\tvalid_0's auc: 0.988922\n",
      "[43]\tvalid_0's auc: 0.989258\n",
      "[44]\tvalid_0's auc: 0.989294\n",
      "[45]\tvalid_0's auc: 0.989252\n",
      "[46]\tvalid_0's auc: 0.98919\n",
      "[47]\tvalid_0's auc: 0.989092\n",
      "[48]\tvalid_0's auc: 0.989181\n",
      "[49]\tvalid_0's auc: 0.989228\n",
      "[50]\tvalid_0's auc: 0.989165\n",
      "[51]\tvalid_0's auc: 0.989136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\96212\\anaconda3\\envs\\ML\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[52]\tvalid_0's auc: 0.9891\n",
      "[53]\tvalid_0's auc: 0.988945\n",
      "[54]\tvalid_0's auc: 0.988894\n",
      "[55]\tvalid_0's auc: 0.988858\n",
      "[56]\tvalid_0's auc: 0.98878\n",
      "[57]\tvalid_0's auc: 0.988765\n",
      "[58]\tvalid_0's auc: 0.98877\n",
      "[59]\tvalid_0's auc: 0.988884\n",
      "[60]\tvalid_0's auc: 0.988877\n",
      "[61]\tvalid_0's auc: 0.988797\n",
      "[62]\tvalid_0's auc: 0.988668\n",
      "[63]\tvalid_0's auc: 0.988902\n",
      "[64]\tvalid_0's auc: 0.988926\n",
      "[65]\tvalid_0's auc: 0.988846\n",
      "[66]\tvalid_0's auc: 0.988818\n",
      "[67]\tvalid_0's auc: 0.988741\n",
      "[68]\tvalid_0's auc: 0.988815\n",
      "[69]\tvalid_0's auc: 0.98878\n",
      "[70]\tvalid_0's auc: 0.988869\n",
      "[71]\tvalid_0's auc: 0.989045\n",
      "[72]\tvalid_0's auc: 0.988957\n",
      "[73]\tvalid_0's auc: 0.988955\n",
      "[74]\tvalid_0's auc: 0.98894\n",
      "[75]\tvalid_0's auc: 0.988999\n",
      "[76]\tvalid_0's auc: 0.989079\n",
      "[77]\tvalid_0's auc: 0.98895\n",
      "[78]\tvalid_0's auc: 0.988959\n",
      "[79]\tvalid_0's auc: 0.989018\n",
      "[80]\tvalid_0's auc: 0.98906\n",
      "[81]\tvalid_0's auc: 0.988974\n",
      "[82]\tvalid_0's auc: 0.989025\n",
      "[83]\tvalid_0's auc: 0.989004\n",
      "[84]\tvalid_0's auc: 0.989086\n",
      "[85]\tvalid_0's auc: 0.988967\n",
      "[86]\tvalid_0's auc: 0.989119\n",
      "[87]\tvalid_0's auc: 0.98917\n",
      "[88]\tvalid_0's auc: 0.989222\n",
      "[89]\tvalid_0's auc: 0.989258\n",
      "[90]\tvalid_0's auc: 0.989219\n",
      "[91]\tvalid_0's auc: 0.989227\n",
      "[92]\tvalid_0's auc: 0.989307\n",
      "[93]\tvalid_0's auc: 0.989242\n",
      "[94]\tvalid_0's auc: 0.989236\n",
      "[95]\tvalid_0's auc: 0.989255\n",
      "[96]\tvalid_0's auc: 0.989176\n",
      "[97]\tvalid_0's auc: 0.989258\n",
      "[98]\tvalid_0's auc: 0.989319\n",
      "[99]\tvalid_0's auc: 0.989449\n",
      "[100]\tvalid_0's auc: 0.989386\n",
      "[101]\tvalid_0's auc: 0.98942\n",
      "[102]\tvalid_0's auc: 0.98939\n",
      "[103]\tvalid_0's auc: 0.989366\n",
      "[104]\tvalid_0's auc: 0.989396\n",
      "[105]\tvalid_0's auc: 0.989375\n",
      "[106]\tvalid_0's auc: 0.989411\n",
      "[107]\tvalid_0's auc: 0.989358\n",
      "[108]\tvalid_0's auc: 0.989348\n",
      "[109]\tvalid_0's auc: 0.989344\n",
      "[110]\tvalid_0's auc: 0.98925\n",
      "[111]\tvalid_0's auc: 0.989266\n",
      "[112]\tvalid_0's auc: 0.989235\n",
      "[113]\tvalid_0's auc: 0.989322\n",
      "[114]\tvalid_0's auc: 0.989324\n",
      "[115]\tvalid_0's auc: 0.989292\n",
      "[116]\tvalid_0's auc: 0.98927\n",
      "[117]\tvalid_0's auc: 0.989268\n",
      "[118]\tvalid_0's auc: 0.989217\n",
      "[119]\tvalid_0's auc: 0.989208\n",
      "[120]\tvalid_0's auc: 0.98917\n",
      "[121]\tvalid_0's auc: 0.989183\n",
      "[122]\tvalid_0's auc: 0.989179\n",
      "[123]\tvalid_0's auc: 0.989177\n",
      "[124]\tvalid_0's auc: 0.989186\n",
      "[125]\tvalid_0's auc: 0.98917\n",
      "[126]\tvalid_0's auc: 0.989198\n",
      "[127]\tvalid_0's auc: 0.989261\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's auc: 0.989703\n"
     ]
    }
   ],
   "source": [
    "test_data=select_by_lgb(train,train_label,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>averge</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.348743</td>\n",
       "      <td>0.249435</td>\n",
       "      <td>0.299089</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.009616</td>\n",
       "      <td>0.047303</td>\n",
       "      <td>0.028459</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.011815</td>\n",
       "      <td>0.228009</td>\n",
       "      <td>0.119912</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.046929</td>\n",
       "      <td>0.040334</td>\n",
       "      <td>0.043631</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.067776</td>\n",
       "      <td>0.259232</td>\n",
       "      <td>0.163504</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.006813</td>\n",
       "      <td>0.025109</td>\n",
       "      <td>0.015961</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.993524</td>\n",
       "      <td>0.960063</td>\n",
       "      <td>0.976794</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.005568</td>\n",
       "      <td>0.025115</td>\n",
       "      <td>0.015342</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.993524</td>\n",
       "      <td>0.960063</td>\n",
       "      <td>0.976794</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.005581</td>\n",
       "      <td>0.025109</td>\n",
       "      <td>0.015345</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1    averge  label\n",
       "0    0.348743  0.249435  0.299089      0\n",
       "1    0.009616  0.047303  0.028459      0\n",
       "2    0.011815  0.228009  0.119912      0\n",
       "3    0.046929  0.040334  0.043631      0\n",
       "4    0.067776  0.259232  0.163504      0\n",
       "..        ...       ...       ...    ...\n",
       "995  0.006813  0.025109  0.015961      0\n",
       "996  0.993524  0.960063  0.976794      1\n",
       "997  0.005568  0.025115  0.015342      0\n",
       "998  0.993524  0.960063  0.976794      1\n",
       "999  0.005581  0.025109  0.015345      0\n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#test_data就是5折交叉验证中5次预测的结果\n",
    "pre_y=pd.DataFrame(test_data).T\n",
    "#将5次预测的结果求取平均值，当然也可以使用其他的方法\n",
    "pre_y['averge']=pre_y[[i for i in range(2)]].mean(axis=1)\n",
    "#因为竞赛需要你提交最后的预测判断，而模型给出的预测结果是概率，因此我们认为概率>0.5的即该患者有糖尿病，概率<=0.5的没有糖尿病\n",
    "pre_y['label']=pre_y['averge'].apply(lambda x:1 if x>0.5 else 0)\n",
    "pre_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 结果提交\n",
    "\n",
    "> Tips：在本环节中，我们需要将最后的预测结果提交到数据竞赛平台中，需要注意的是我们要严格按照竞赛平台的文件格式提交要求。\n",
    "\n",
    "> - 提交地址: https://challenge.xfyun.cn/topic/info?type=diabetes&ch=ds22-dw-zmt01\n",
    "\n",
    "> 其中result.csv就是需要提交到平台的文件，进入到数据竞赛平台，点击`提交结果`，选择result.csv文件即可完成结果提交"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=pd.read_csv('data/提交示例.csv')\n",
    "result['label']=pre_y['label']\n",
    "result.to_csv('result.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 后续\n",
    "\n",
    "经过简单的学习，我们完成了糖尿病遗传风险检测挑战赛的baseline任务，接下来应该怎么做呢？主要是以下几个方面：\n",
    "\n",
    "- 继续尝试不同的预测模型或特征工程来提升模型预测的准确度\n",
    "- 加入Datawhale比赛交流群，获取其他更加有效的上分信息\n",
    "- 查阅糖尿病遗传风险预测相关资料，获取其他模型构建方法\n",
    "- ...\n",
    "\n",
    "总之，就是在baseline的基础上不断的改造与尝试，通过不断的实践来提升自己的数据挖掘能力，正所谓【**纸上得来终觉浅，绝知此事要躬行**】，也许你熟练掌握机器学习的相关算法，能熟练推导各种公式，但如何将学习到的方法应用到实践工程中，需要我们不断的尝试与改进，没有一个模型是一步所得，向最后的冠军冲击~\n",
    "\n",
    "Ref：\n",
    "\n",
    "- [鱼佬：从数据竞赛到工作！](https://mp.weixin.qq.com/s?__biz=MzIyNjM2MzQyNg==&mid=2247571357&idx=1&sn=96c9a284105588cb458e0b92925f2297&scene=21#wechat_redirect)\n",
    "- [下一站，向冠军冲击！](https://mp.weixin.qq.com/s/d7dXGYnF4NZuuazktK4SXQ)\n",
    "- [我的机器学习之路](https://mp.weixin.qq.com/s/2-V1kFbSzi3Z5UJ7GV_WBw)\n",
    "- [我的机器学习入门清单及路线！](https://mp.weixin.qq.com/s/KeD9kPG8PowlKrz69zSHNQ)\n",
    "- [机器学习神器Scikit-Learn保姆教程！](https://mp.weixin.qq.com/s/4NSVh1HniNT4CGakzHxm1w)\n",
    "- [《Datawhale人工智能培养方案》发布！](https://mp.weixin.qq.com/s/JY9RcZ-EquNWdT5k6tLEWg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('ML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "0e709c4988dd496cad6cf9f2692ac7822b9995cabcb3fe3c2bc9d931b0e033f9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

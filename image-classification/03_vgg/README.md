# 用于大规模图像识别的非常深的卷积网络 （vgg）——VERY DEEP CONVOLUTIONAL NETWORKS FOR LARGE-SCALE IMAGE RECOGNITION

发表于2015

# 作者



![image-20220816200238168](https://gitee.com/shuangshuang853/picture-bed/raw/master/image-20220816200238168.png)

视觉几何学组，牛津大学工程科学系

VGG在2014年由牛津大学著名研究组vGG (Visual GeometryGroup)提出

# 摘要

![image-20220816200910211](https://gitee.com/shuangshuang853/picture-bed/raw/master/image-20220816200910211.png)

​	在这项工作中，我们研究了**卷积网络深度对其精度的影响**。我们的主要贡献是**使用非常小（3×3）卷积滤波器**的体系结构**对增加深度的网络**进行了全面的评估，这表明通过将深度推到**16-19个权重层**，可以实现对现有技术配置的显著改进。这些发现是我们2014年**ImageNet挑战**提交的基础，我们的团队在**定位任务和分类任务**中分别获得了**第一名和第二名**。我们还表明，我们的表示可以很好地推广到其他数据集，在那里它们实现了最先进的结果。我们已经公开了两种性能最好的ConvNet模型，以促进在计算机视觉中使用深度视觉表示的进一步研究。



# 5 结论

​	在这项工作中，我们评估了非常深的卷积网络（多达19个权重层）的大尺度图像分类。结果表明，表示深度有利于分类精度，并且可以使用传统的ConvNet挑战数据集上实现最先进的性能(LeCun等人，1989；克里日夫斯基等人，2012)，大幅增加深度。在附录中，我们还展示了我们的模型可以很好地推广到广泛的任务和数据集，匹配或优于围绕较不深的图像表示构建的更复杂的识别管道。我们的研究结果再次证实了深度在视觉表征中的重要性。



# 1 引言

​	

​	卷积网络(ConvNets)最近在大规模图像和视频识别方面取得了巨大成功（克里热夫斯基等，2012；泽勒和费格斯，2013；塞马尼等，2014；西蒙扬和齐塞曼，2014），由于大型公共图像存储库，如ImageNet（邓等，2009）和高性能计算系统，如gpu或大规模分布式集群（Dean等，2012）。特别是，一个重要的角色在深度视觉识别架构的进步被ImageNet大规模视觉识别挑战(ILSVRC)（俄罗斯萨科夫斯基等，2014），作为几代的大规模图像分类系统，从高维浅特征编码（佩罗宁等，2010）(ILSVRC-2011)深网络（克里日夫斯基等，2012）(ILSVRC-2012的赢家)。

​	随着convnet成为计算机视觉领域的一种商品，人们已经多次尝试改进克里日夫斯基等人（2012）的原始架构，以获得更好的准确性。例如，在ILSVRC-2013中表现最好的提交(Zeiler&费格斯，2013；Sermanet等人，2014)使用了**更小的接受窗口大小**和**更小的第一卷积层的步幅**。另一项改进是在整个图像和多个尺度上密集地对网络进行训练和测试(Sermanetetal.，2014；霍华德，2014)。在本文中，我们讨论了ConvNet架构设计的另一个重要方面——它的深度。为此，我们修复了体系结构的其他参数，并通过添加更多的卷积层来稳步增加网络的深度，这是可行的，因为在所有层中都使用了非常小的（3×3）卷积滤波器。

​	因此，我们想出了更准确的网络架构，不仅实现最先进的精度ILSVRC分类和本地化任务，但也适用于其他图像识别数据集，他们实现优秀的性能即使作为一个相对简单的管道的一部分(例如深度特性分类的线性SVM没有微调)。我们已经发布了我们的两个性能最好的模型1，以促进进一步的研究。

​	论文的其余部分组织如下。在第二节中，我们描述了我们的ConvNet配置。图像分类训练和评估的细节，然后在章节中介绍。3、和相应的在第二节的ILSVRC分类任务上进行了配置比较。 4.第二节。5、总结了论文。为了完整起见，我们还在附录A中描述和评估了我们的ILSVRC-2014对象定位系统，并在附录b中讨论了将非常深的特征推广到其他数据集。最后，附录C包含了主要的论文修订列表。



# 2 卷积结构 CONVNET CONFIGURATIONS

​	为了衡量在公平的环境下增加深度所带来的改进，我们所有的网络层配置都使用相同的原则设计，灵感来自Ciresan等人（2011）；克里日夫斯基等人（2012）。

​	2.1)，在本节中，我们首先描述ConvNet配置的通用布局。

​	2.2)，然后详细说明在评估中使用的具体配置(第二节。

​	2.3)，然后讨论了我们的设计选择，并与章节中的现有技术进行了比较。

## 2.1 结构

​	在训练期间，我们的convnet的输入是一个固定大小的 224×224 RGB图像。我们所做的唯一预处理是从每个像素中减去在训练集上计算的平均RGB值。图像通过一堆卷积(conv)传递。在图层中，我们使用一个非常小的接受域的过滤器：3×3（这是捕获左/右，上/下，中心概念的最小大小）。在其中一种配置中，我们还使用了1×1卷积滤波器，这可以看作是输入通道的线性变换（然后是非线性）。卷积步幅固定为1像素；conv的空间填充。层输入在卷积后保持空间分辨率，即3×3conv的填充为1像素。层空间池化由五个最大池化层执行，它们遵循一些conv。图层(不是所有的conv。图层后面是最大池化处理)。最大池化是在一个2×2像素的窗口上执行的，步幅为2。卷积层的堆栈（在不同的架构中有不同的深度）之后是三个完全连接(FC)层：前两个层每个有4096个通道，第三个层执行1000路I

## 2.2 构造

​	本文中评估的ConvNet配置见表1，每列一个。在下面，我们将提到这些网的名字(A-E)。所有的配置都遵循章节中介绍的通用设计。2.1，仅不同于深度：从网络A的11层(8conv和3个FC层)到网络E中的19个权重层(16个conv。和3个FC层)。conv的宽度。层（通道的数量）相当小，从第一层的64层开始，然后在每个最大池化层后增加2倍，直到达到512层。在表2中，我们报告了每个配置的参数的数量。尽管深度很大，但我们的网中的权重数并不大于较浅的conv网中的权重数。图层的宽度和接受野(144M的权重(Sermanetetal.，2014))。

​	在表2中，我们报告了每个配置的参数的数量。尽管深度很大，但我们的网中的权重数并不大于一个较浅的网中的权重数。图层的宽度和接受野(144M的权重(Sermanetetal.，2014))。

## 2.3 讨论

​	我们的ConvNet配置与ILSVRC-2012（克里热夫斯基等人，2012）和ILSVRC-2013比赛（泽勒和费格斯，2013）的顶级参赛作品中使用的配置非常不同；塞尔马内等人，2014)。而不是在第一个组中使用相对较大的接受域。层（例如，11步×11步4（克里日夫斯基等人，2012），或7×7步2（泽勒和费格斯，2013；塞马尼等人，2014）），我们在整个网络中使用非常小的3×3接受域，它们与每个像素的输入进行卷积（步幅1）。很容易看到一堆两个3×3conv。各层（中间没有空间池化）的有效接受域为5×5；3



<img src="https://gitee.com/shuangshuang853/picture-bed/raw/master/image-20220816202822892.png" alt="image-20220816202822892" style="zoom:67%;" />

表1：ConvNet配置（如列所示）。随着添加更多的层（添加的层），配置的深度从左(A)向右(E)增加（添加的层以粗体显示）。卷积层参数表示为“通道的对接受场齐h数”。为了简洁起见，我们没有将ReLU的激活函数显示出来。 <u>conv的stride为1，padding为1，maxpooling的size为2，stride为2.</u>

![image-20220817092137361](https://gitee.com/shuangshuang853/picture-bed/raw/master/image-20220817092137361.png)



![image-20220816203710829](https://gitee.com/shuangshuang853/picture-bed/raw/master/image-20220816203710829.png)

​	**亮点**：通过堆叠多个 3×3 的卷积核来替代大尺度卷积核（减少所需参数）

### 	CNN感受野

​	在卷积神经网络中，决定某一层输出结果中一个元素所对应的输入层的区域大小，被称作感受野(receptive field)。通俗的解释是，输出feature map上的一个单元对应输入层上的区域大小。

![image-20220817090256477](https://gitee.com/shuangshuang853/picture-bed/raw/master/image-20220817090256477.png)



![image-20220817090415315](https://gitee.com/shuangshuang853/picture-bed/raw/master/image-20220817090415315.png)

3个 3×3 的卷积核：

![image-20220817090842631](https://gitee.com/shuangshuang853/picture-bed/raw/master/image-20220817090842631.png)

​	可以通过堆叠两个3x3的卷积核替代5x5的卷积核，堆叠三个3x3的卷积核替代7x7的卷积核，拥有相同的感受野。

​	使用7x7卷积核所需参数，与堆叠三个3x3卷积核所需参数(假设输入输出channel为C)

![image-20220817091044516](https://gitee.com/shuangshuang853/picture-bed/raw/master/image-20220817091044516.png)



​	这些层有一个7×7的有效接受野。那么，我们通过使用三个3×3转换的堆栈获得了什么。图层而不是单一的7×7图层？首先，我们加入了三个非线性整流层，而不是单一的一个，这使得决策函数更具鉴别性。其次，我们减少了参数的数量：假设三层3×3卷积栈的输入和输出都有C通道，该栈由3 (3^2 * C^2)=27C^2权值参数化；同时，一个7×7conv层将需要7^2 * C^2=49 * C^2参数，即增加81%。这可以看作是对7×7conv实施了规则化。滤波器，迫使它们通过3×3滤波器（之间注入非线性）。



​	1×1conv的合并。层(配置C，表1)是一种在不影响conv的接受域的情况下增加决策函数的非线性的方法。层即使在我们的情况下，1×1卷积本质上是在同维空间上的线性投影（输入和输出通道的数量是相同的），校正函数引入了一个额外的非线性。应该注意的是，1×1conv。最近，在Lin等人（2014）的“网络中的网络”架构中使用了层。

​	Ciresan等人（2011）之前曾使用过小型卷积滤波器，但它们的网络深度明显低于我们的，而且它们没有在大规模ILSVRC数据集上进行评估。Goodfell等人（2014）将深度ConvNets（11个重量层）应用于街道数字识别任务，结果表明，深度的提高会导致更好的性能。GoogLeNet(Szegedy等人，2014)是ILSVRC-2014分类任务的最佳条目，是独立于我们的工作开发的，但相似之处在于它基于非常深入的网络（22个权重层）和小的卷积滤波器（除了3×3，它们也使用1×1和5×5卷积）。然而，它们的网络拓扑结构比我们的更复杂，并且特征图的空间分辨率在第一层被更积极地降低，以减少计算量。如图所示。4.5，我们的模型在单网络分类精度方面优于Szegedy等人（2014）。



# 3 分类框架

​	在上一节中，我们将详细介绍网络配置的细节。在本节中，我们将描述分类卷积神经网络训练和评估的细节。

## 3.1 训练

​	ConvNet训练程序通常遵循Krizhevest等人（2012）（除了从多尺度训练图像中采样输入作物，如后面所述）。也就是说，训练是通过使用具有动量的小批量梯度下降(基于反向传播(LeCunetal.，1989))优化多项式逻辑回归目标来进行的。批处理大小设置为256，动量设置为0.9。训练通过权重衰减(L2惩罚乘数设置为5.10−4)和前两个全连接层的退出正则化（退出比设置为0.5）进行正则化。学习速率最初被设置为10−2，然后当验证集的准确性停止提高时，它被降低了10倍。学习速率共下降了3次，经过370K次迭代(74个epoch)后停止学习。我们推测，尽管与(Krizheves基等人，2012)相比，我们的网的参数数量更大，但由于更大深度和更小的(a)隐式正则化，网需要更少的时代来收敛。过滤器的大小；(b)预初始化的某些层。

​	网络权值的初始化是很重要的，因为由于深度网络中梯度的不稳定，糟糕的初始化可能会阻碍学习。为了解决这个问题，我们开始训练配置A（表1），它足够浅，可以进行随机初始化训练。然后，当训练更深层次的架构时，我们用净A层初始化了前四个卷积层和最后三个卷积层的完全连接层（中间层被随机初始化）。我们没有降低预初始化层的学习率，而是允许它们在学习过程中发生变化。对于随机初始化（如适用的话），我们从一个具有零均值和10−2方差的正态分布中抽样权重。这些偏差被初始化为零。值得注意的是，在将论文提交后，我们发现，通过使用Glorot&Bengio（2010）的随机初始化程序，可以在没有预先训练的情况下初始化权重。

​	为了获得固定大小的224×224ConvNet输入图像，它们从重新缩放的训练图像中随机裁剪(每次SGD迭代每个图像裁剪一次)。为了进一步增加训练集，作物进行了随机水平翻转和随机RGB颜色变化(Krizhevestyetal.，2012)。训练图像的重新调整将被解释如下。

​	训练图像大小。设S是各向同性重新缩放的训练图像的最小边，从其中裁剪ConvNet输入(我们也将S称为训练量度)。虽然作物大小固定为224×224，但原则上S可以接受任何不小于224的值：对于S=224，作物将捕获整个图像统计数据，完全跨越训练图像的最小侧；对于S≫224，作物将对应于图像的一小部分，包含一个小对象或对象部分。

​	我们考虑了两种设置训练尺度S的方法。第一种是固定S，它对应于单尺度训练（注意，采样作物内的图像内容仍然可以代表多尺度图像统计）。在我们的实验中，我们评估了在两个固定尺度下训练的模型：S=256（已在现有技术中广泛使用（克里热夫斯基等人，2012；泽勒和费格斯，2013；塞尔马尼等人，2014））和S=384。给定一个卷积Net配置，我们首先使用S=256训练网络。为了加快S=384网络的训练，我们使用S=256预训练的权值初始化，我们使用较小的初始学习率为10−3。

​	设置S的第二种方法是多尺度训练，其中每个训练图像通过从一定范围内随机采样S[Smin，Smax](我们使用Smin=256和Smax=512)。由于图像中的物体可以大小不同，所以在训练中考虑到这一点是有益的。这也可以看作是训练集增强的规模抖动，其中一个单一的模型被训练来识别在广泛的尺度上的物体。出于速度上的原因，我们通过微调具有相同配置的单尺度模型的所有层来训练多尺度模型，并使用固定的S=384进行预训练。

## 3.2 测试

​	在测试时，给定一个训练过的卷积神经和一个输入图像，它按照以下方法进行分类。首先，它被各向同性重新缩放到预定义的最小图像侧，表示为Q（我们也称它称为测试尺度）。我们注意到Q并不一定等于训练量表S(正如我们将在Sect中所示。4、对每个S使用几个Q值可以提高性能)。然后，将该网络以一种类似于(Sermanetetal.，2014)的方式密集地应用于重新调整后的测试图像上。即，全连接的层首先转换为卷积层(第一个FC层转换为7×7conv。层，最后两个FC层到1×1conv。层 然后，将所得到的全卷积网络应用于整个（未裁剪的）图像。结果是一个类分数映射，通道数等于类的数量，以及一个可变的空间分辨率，取决于输入图像的大小。最后，为了获得图像的一个固定大小的类分数向量，我们对类分数图进行了空间平均（和合并）。我们还通过图像的水平翻转来增加测试集；将原始图像和翻转图像的软最大类后端进行平均，以获得图像的最终分数。

​	由于全卷积网络应用于整个图像，因此不需要在测试时对多个作物进行采样(Krizhevestetal.，2012)，因此效率较低，因为它需要对每个作物进行网络重新计算。同时，正如Szegedy et al.等人（2014）所做的那样，使用大量作物可以提高精度，因为与全卷积网络相比，它对输入图像的采样更精细。此外，多作物评估补充密集评估由于不同的卷积边界条件：当应用卷积网络作物，卷积特征地图填充零，而在密集评估的情况下填充相同的作物自然来自图像的邻近部分（由于卷积和空间池），这大大增加了整个网络接受域，所以更多的上下文。虽然我们相信在实践中增加计算时间的多个作物不证明潜在的收益，参考我们也评估网络使用50作物每规模（5×5常规网格2翻转），总共150作物超过3尺度，相当于144作物4尺度Szegedyetal.（2014）。

## 3.3 实施细节

​	我们的实现来源于公开C++ Caffe工具箱（贾，2013）（分支在2013年12月），但包含一些重要的修改，允许我们执行培训和评估多个图形处理器安装在一个系统，以及火车和评估全尺寸（未裁剪）图像在多个尺度（如上所述）。多GPU训练利用数据并行性，将每批训练图像分成几个GPU批，在每个GPU上并行处理。计算GPU批梯度后，取平均值，得到整个批的梯度。梯度计算在各个GPU上都是同步的，所以其结果与在单个GPU上进行训练时完全相同。

​	虽然更复杂的方法加速网络训练最近提出（克里日夫斯基，2014），采用模型和数据并行性不同层的网络，我们发现我们的概念上更简单的方案已经提供了3.75倍的现成的4-GPU系统相比，使用一个GPU。在一个配备了四个NVIDIA泰坦黑色图形处理器的系统上，根据架构，训练一个网络需要2-3周的时间。



# 4 分类实验

​	**数据集**。在本节中，我们将展示在ILSVRC-2012数据集(用于ILSVRC 2012-2014挑战)上所描述的ConvNet架构上获得的图像分类结果。数据集包括1000个类的图像，并分为三组：训练（130万张图像）、验证(50K张图像)和测试(100K个保留类标签的图像)。分类性能通过两个指标进行评估：top-1和top-5的误差。前者是一种多类分类错误，即错误分类图像的比例；后者是在ILSVRC中使用的主要评价标准，并计算为地面真实类别在 top-5 预测类别之外的图像的比例。对于大多数实验，我们使用验证集作为测试集。在测试集上，某些实验也进行，并作为ILSVRC-2014比赛的“VGG”团队参赛作品提交给官方ILSVRC服务器（俄罗斯萨科夫斯基等人，2014）



## 4.1 单尺度评价

​	我们首先用章节中描述的层配置在单一尺度上评估单个ConvNet模型的性能。2.2.测试图像大小设置如下：固定S的Q=S，抖动S∈(Smin+Smax)的Q=0.5[Smin，Smax]。的结果如表3所示。

​	首先，我们注意到使用局部响应归一化(A-LRN网络)在没有任何归一化层的改进模型A。因此，我们不在更深层次的架构中使用标准化(B-E)。

​	其次，我们观察到分类误差随着ConvNet深度的增加而减小：从A的11层减少到e的19层。值得注意的是，尽管深度相同，配置C(其中包含3个1×1conv。层)，性能比配置D差，后者使用3×3conv。贯穿整个网络的图层。这表明，虽然额外的非线性确实有帮助(C比B更好)，但通过使用conv来捕获空间上下文也很重要。具有非平凡接受域的滤波器(D优于C)。当深度达到19层时，我们的体系结构的错误率达到饱和，但更深的模型可能有利于更大的数据集。我们还比较了净B与55×5conv。层，由B通过替换每对3×3conv。层与单个5×5conv。层(它有相同的接受域解释。2.3).浅层网的前1个误差比B（中心作物）高7%，这证实了具有较小滤波器的深层网优于具有较大滤波器的浅层网。

​	最后，在训练时的尺度抖动(S∈[256；512])明显比训练固定最小边的图像(S=256或S=384)，即使在测试时使用单一的尺度。这证实了通过尺度抖动增强训练集确实有助于捕获多尺度图像统计数据。

<img src="https://gitee.com/shuangshuang853/picture-bed/raw/master/image-20220816211150157.png" alt="image-20220816211150157" style="zoom:67%;" />



## 4.2 多尺度评估

​	在单一尺度上评估了ConvNet模型后，我们现在评估了测试时尺度抖动的影响。它包括在一个测试图像的几个重新缩放的版本(对应于不同的Q值)上运行一个模型，然后平均得到的类后验。考虑到训练量表和测试量表之间的很大差异会导致性能下降，用固定S训练的模型在三个测试图像大小上进行评估，接近训练一个：Q={S−32，S，S+32}。同时，训练时的尺度抖动允许网络在测试时应用于更广泛的尺度范围，因此使用变量S∈[Smin；Smax]训练的模型在更大的大小Q={Smin，0.5(Smin+Smax)，Smax}范围内进行评估。

​	结果如表4所示，表明测试时的尺度抖动导致更好的性能（与在单一尺度上评价相同的模型相比，如表3所示）。与之前一样，最深的配置(D和E)表现最好，规模抖动比固定最小边训练更好。我们在验证集上的最佳单网络性能是 24.8%/7.5% top1/top5 错误（在表4中以粗体突出显示）。在测试集上，配置E达到了7.3%的top-5 error 。

![image-20220816211620853](https://gitee.com/shuangshuang853/picture-bed/raw/master/image-20220816211620853.png)

## 

## 4.3 MULTI-CROP 评价

​	在表5中，我们比较了密集的ConvNet评价和多作物评价(见第二节。3.2的细节)。我们还通过平均它们的软大输出来评估这两种评估技术的互补性。可以看出，使用多种作物的性能略优于密集评估，而且这两种方法确实是互补的，因为它们的组合性能优于每一种方法。如上所述，我们假设这是由于对卷积边界条件的不同处理。

![image-20220816212053749](https://gitee.com/shuangshuang853/picture-bed/raw/master/image-20220816212053749.png)



## 4.4 CONVNET FUSION

​	到目前为止，我们评估了各个ConvNet模型的性能。在这部分的实验中，我们通过平均它们的软最大类后验来组合几个模型的输出。由于模型的互补性，这提高了性能，并在2012年（克里热夫斯基等人，2012）和2013年（泽勒和费格斯，2013,2013；塞尔马尼等人，2014）。

​	结果如表6所示。到ILSVRC提交时，我们只训练了单尺度网络，以及多尺度模型D（通过只微调全连接的层，而不是所有的层）。7个网络的集成有7.3%的ILSVRC测试误差。提交后，我们只考虑了两个表现最好的多尺度模型(配置D和E)的集合，使用密集评估将测试误差降低到7.0%，使用密集和多作物联合评估将测试误差降低到6.8%。作为参考，我们表现最好的单个模型达到了7.1%的误差(模型E，表5)。



## 4.5 COMPARISON WITH THE STATE OF THE ART

​	最后，我们将我们的结果与表7中的最新技术水平进行了比较。在ILSVRC-2014挑战的分类任务中（俄罗斯萨科夫斯基等人，2014），我们的“VGG”团队获得了第二名，使用7个模型的集成，测试误差为7.3%。提交后，我们使用两个模型的集成将错误率降低到6.8%。

![image-20220816212833352](https://gitee.com/shuangshuang853/picture-bed/raw/master/image-20220816212833352.png)

​	从表7中可以看出，我们非常深入的ConvNets的表现明显优于上一代的模型，在ILSVRC-2012和ILSVRC-2013的比赛中取得了最好的效果。我们的结果也与分类任务获胜者（谷歌误差6.7%）具有竞争力，大大优于ILSVRC-2013获奖提交的clarfai，在外部训练数据下达到11.2%，在没有训练数据的情况下达到11.7%。这是值得注意的，因为我们的最佳结果是通过结合两个模型——明显少于在大多数ILSVRC提交中使用的模型。在单网性能方面，我们的架构获得了最佳的结果（7.0%的测试错误），比单个GoogLeNet高出0.9%。值得注意的是，我们并没有背离LeCun等人（1989）的经典ConvNet架构，而是通过大幅增加深度而改进了它。

![image-20220816220331071](https://gitee.com/shuangshuang853/picture-bed/raw/master/image-20220816220331071.png)








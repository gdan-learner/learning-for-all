# Deep Residual Learning for Image Recognition用于图像识别的深度残差学习

发表于2015

# 作者



![image-20220817213920711](https://gitee.com/shuangshuang853/picture-bed/raw/master/image-20220817213920711.png)

ResNet在2015年由**微软实验室**提出，斩获当年lmageNet竞赛中分类任务第一名，目标检测第一名。获得coco数据集中目标检测第一名;图像分割第一名。

网络中的亮点:

- 超深的网络结构(突破1000层)
- 提出residual模块
- 使用Batch Normalization加速训练(丢弃dropot)

# 摘要

​	

![image-20220817214044379](https://gitee.com/shuangshuang853/picture-bed/raw/master/image-20220817214044379.png)

# 5 结论

​	



# 1 引言

​	![image-20220818091958408](https://gitee.com/shuangshuang853/picture-bed/raw/master/image-20220818091958408.png)



![image-20220817214116980](https://gitee.com/shuangshuang853/picture-bed/raw/master/image-20220817214116980.png)



# 2 相关工作

​	在图像识别中，VLAD [18]是一种由残差向量相对于字典进行编码的表示，Fisher Vector [30]可以表述为VLAD的概率版本[18]。它们都是 用于图像检索和分类的强大浅层表示[4，47]。对于向量量化，编码残差向量[17]被证明比编码原始向量更有效。

​	在低级视觉和计算机图形学中，为了 求解偏微分方程（PDE），广泛使用的多网格方法[3]将系统重新表述为多个尺度的子问题，其中每个子问题负责较粗尺度和较精细尺度之间的残差解。多网格的交替e 是分层基预处理 [44， 45]，它依赖于表示两个尺度之间的残差向量的变量。已经证明[3， 44， 45]这些求解器收敛的速度比标准求解器收敛得快得多，标准求解器不知道解的 残差性质。这些方法表明，良好的重新配方或预处理可以简化优化。

​	训练多层感知器（MLP）的早期实践是添加一个从网络输入连接到输出的线性层[33，48]。在[43， 24]中，一些中间层直接连接到辅助分类器，以解决消失/爆炸梯度。

​	[38， 37， 31， 46]的论文提出了通过捷径连接实现的居中层响应、梯度和传播误差的方法。在[43]中，“起始”层由一个快捷方式分支和几个更深的分支组成。

​	在我们的工作的同时，“高速公路网络”[41，42]提供了具有门控功能的快捷方式连接[15]。这些门是依赖于数据的，并且具有e 参数，这与我们无参数的身份快捷方式相反。当门控快捷键“关闭”（接近于零）时，高速公路网络中的图层表示 非残差 函数。相反，我们的公式总是学习残差函数;我们的身份捷径永远不会关闭，所有的信息总是通过，还有额外的残差函数需要学习。此外，高方式网络没有表现出深度极高（例如，超过100层）的精度增益。

# 3 残差学习

​	让我们将 H（x） 视为底层映射，由几个堆叠层（不一定是整个网络）拟合，x 表示这些层中第一个层的输入。如果假设多个非线性层可以渐近地近似于复杂函数 ，那么它等价于假设它们可以渐近地近似残差函数，即H（x） −x（假设输入和输出具有相同的维度）。

​	因此，我们不是期望堆叠层近似 H（x），而是显式地让这些层近似残差函数 F（x） ：= H（x） −x。因此，原始函数变为 F（x）+x。虽然这两种形式都应该能够渐近地接近所需的函数（如假设的那样），但学习的难易程度可能不同

![image-20220817214305397](https://gitee.com/shuangshuang853/picture-bed/raw/master/image-20220817214305397.png)

​	这种重新表述的动机是关于退化问题的反直觉现象（图1，左）。正如我们在引言中所讨论的，如果添加的层可以构造为身份映射，则较深的模型应比其较浅的对应物具有小的训练误差。降级问题表明，求解器在通过多个非线性层近似单位映射时可能存在困难。通过残差学习重新表述，如果恒等映射是最优的，则求解器可以简单地将多个 非线性层的权重驱动到零以接近恒等映射。

​	在实际情况下，身份映射不太可能是最优的，但是我们的重新表述可能有助于预先解决问题。如果最优 函数更接近于恒等映射而不是零映射，则求解器参照恒等映射查找扰动应该比将函数作为新函数学习更容易。我们通过实验（图7）表明，学习的 残差函数通常具有较小的响应，这表明恒等映射提供了合理的预处理。

​	通过快捷方式进行身份映射：

![残差模块](https://gitee.com/shuangshuang853/picture-bed/raw/master/image-20220817214404666.png)

x 和 y 是所考虑的层的输入和输出向量。函数 F（x，{Wi}） 表示要学习的残差映射。

![image-20220817214428523](https://gitee.com/shuangshuang853/picture-bed/raw/master/image-20220817214428523.png)

其中 σ 表示 ReLU [29]，省略偏差以简化符号。

操作 F + x 通过快捷方式连接和元素加法执行。我们采用加法后的第二个非线性（即σ（y），见图2）

如果F只有一层，Eqn.（1）类似于线性层：y = W1x + x，

上述符号是关于全连接层的，但它们适用于卷积层。

函数 F（x，{Wi}） 可以表示多个卷积层。

快捷连接既不引入额外的参数，也不引入计算复杂性。

这不仅在实践中具有吸引力，而且在我们对普通网络和残差网络之间的比较中也很重要。

我们可以公平地比较同时具有相同参数，深度，宽度和计算成本的plain/残差网络（除了可忽略不计的元素加法）。

x 和 F 的维数在方程 （1） 中必须相等。

如果不是这种情况（例如，在更改输入/输出通道时），我们可以通过快捷方式连接执行线性投影Ws以匹配尺寸：

![image-20220817214526374](https://gitee.com/shuangshuang853/picture-bed/raw/master/image-20220817214526374.png)





![image-20220817214539651](https://gitee.com/shuangshuang853/picture-bed/raw/master/image-20220817214539651.png)

实线与虚线：

![image-20220818094122554](https://gitee.com/shuangshuang853/picture-bed/raw/master/image-20220818094122554.png)



![image-20220818094528313](https://gitee.com/shuangshuang853/picture-bed/raw/master/image-20220818094528313.png)

注意原论文中,右侧虚线残差结构的主分支上，第一个1x1卷积层的步距是2，第二个3x3卷积层步距是1。但在pytorch官方实现过程中是第一个1xi卷积层的步距是1，第二个3x3卷积层步距是2，这样能够在imagenet的top1上提升大概0.5%的准确率。可参考Resnet v1.5。https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch



卷积层大多有3×3个滤波器，并遵循两个简单的设计规则：

（i）对于相同的输出特征图大小，图层具有same个滤波器;

（ii）如果特征图大小减半，则滤波器数量加倍，以保持每层的时间复杂度。我们直接通过步幅为 2 的卷积层执行缩减采样。该网络以 global 平均池化层和具有 softmax 的 1000 路全连接层结束。图3（中）中加权层的总数为34。

与VGG网络相比，我们的模型具有 更少的 滤波器和 更低的 复杂性[40]（图3，左）。我们的 3个 4 层基准有 36 亿个 FLOP（乘法加法），其中

仅占VGG-19（196亿FLOP）的18%。

**残差网络：**

基于中间的普通网络，我们插入快捷方式连接（右），将网络转换为其对应的残差版本。

当输入和输出具有相同的尺寸时，可以直接使用恒等式快捷键（Eqn.（1））（图3中的实线快捷键）。当尺寸增加时（图3中的虚线快捷方式），我们考虑两个选项：

•A：快捷方式仍然执行恒等映射，并填充额外的零个条目以增加维度。此选项不引入任何额外参数;

• B：Eqn.（2） 中的投影快捷方式用于匹配维度（由 1×1 卷积完成）。对于这两个选项，当快捷方式跨越两种大小的要素映射时，它们的步幅为 2。



## 3.4 实现

调整图像大小后，其较短的边在[256，480]中随机采样以进行比例增强[40]。

从图像或其水平翻转中随机抽取224×224裁剪，每像素减去平均值[21]。 使用[21]中的标准颜色增强。

我们在每次卷积之后和激活之前采用批量归一化（BN）[16]，遵循[16]。

我们初始化 [13] 中的权重，并从头开始训练所有普通/残余网络。

我们用SGD 的mini batch size为 256，学习速率从 0.1 开始，当误差稳定时除以 10，模型被训练最多 60 0000 次迭代。我们使用权重衰减 0.0001 和动量 0.9。

我们不使用dropout[13]，遵循[16]中的做法。

在测试中，对于比较研究，我们采用标准的10折验证[21]。

为了获得最佳结果，我们采用[40，12]中的完全卷积形式，并在多个量表上平均分数

（图像调整大小，使较短的边在{224，256，384，480，640}中）。

AlexNet中用PCA做颜色增强。

这里就是RGB上做增强，亮度、饱和度…

## Batch Normalization

Batch Normalization的目的是使我们的一批( Batch)feature map满足均值为0，方差为1的分布规律。

![image-20220818101351502](https://gitee.com/shuangshuang853/picture-bed/raw/master/image-20220818101351502.png)

https://blog.csdn.net/qq_37541097/article/details/104434557



# 迁移学习

1.能够快速的训练出一个理想的结果

2.当数据集较小时也能训练出理想的效果

注意:使用别人预训练模型参数时，要注意别人的预处理方式。

![image-20220818101819494](https://gitee.com/shuangshuang853/picture-bed/raw/master/image-20220818101819494.png)

迁移学习，将浅层网络的参数迁移到新的网络当中。新的网络也就拥有了识别底层通用特征的能力。

常见的迁移学习方式:

- 1.载入权重后训练所有参数
- 2.载入权重后只训练最后几层参数
- 3.载入权重后在原网络基础上再添加一层全连接层，仅训练最后一个全连接层

# 4 实验

## 4.1 **ImageNet分类**

![image-20220817214725560](https://gitee.com/shuangshuang853/picture-bed/raw/master/image-20220817214725560.png)

<u>Down sampling is performed by conv3 1, conv4 1, and conv5 1 with a stride of 2.</u>

尽管深度显著增加，但152层ResNet（113亿FLOP）仍然比VGG-16/19网络（15.3/196亿FLOP）具有更低的复杂性。

表2的结果表明，较深的34层普通网络比较浅的18层普通网具有更高的验证误差，34层普通网在整个训练过程中具有较高的训练误差，尽管18层普通网络的求解空间是34层平网络的子空间。

不太可能是由梯度消失引起的，这些普通网络使用BN [16]进行训练，这确保了前向传播信号具有非零方差。我们还验证了反向传播的梯度在BN中表现出良好的规范。因此，无论是向前还是向后，梯度都不会消失。



![image-20220817214824631](https://gitee.com/shuangshuang853/picture-bed/raw/master/image-20220817214824631.png)

细曲线表示训练误差，粗体曲线表示中心作物的验证误差。

左：18 层和 34 层的普通网络。

右：18 层和 34 层的 ResNet。

在此图中，残差网络没有额外的参数

![image-20220817214835662](https://gitee.com/shuangshuang853/picture-bed/raw/master/image-20220817214835662.png)

​								表 2.ImageNet 验证上的前 1 个错误（% ， 10折验证）ResNets 与普通的网络相比没有额外的参数。

ResNet 将top-1 的错误减少了 3.5%	

在训练集和验证集上，34层ResNet优于18层ResNet（2.8%）

这表明在此设置中，降级问题得到了很好的解决，并且我们设法从增加的深度中获得准确性增益。

当网络“不太深”（此处为18层）时，当前的SGD求解器仍然能够找到普通网络的良好解决方案。 ResNet 通过在早期阶段提供更快的收敛来简化优化。

![image-20220818090129595](https://gitee.com/shuangshuang853/picture-bed/raw/master/image-20220818090129595.png)

表 3.ImageNet 验证上的错误率（%， 10折验证）

VGG-16基于我们的测试。

ResNet-50/101/152属于选项B，仅使用投影来增加维度。

**（A）零填充快捷键用于增加尺寸，并且所有快捷键都是无参数的 （与表 2 和图 4 右侧相同）;**

**（B）投影捷径用于增加维度，其他快捷键是恒等;**

**（C）所有快捷键都是投影。**

所有三个选项都比普通选项好得多。

B比A稍好一些。我们认为这是因为A中的零填充维数确实没有残余学习。

C比B稍微好一些，我们将其归因于许多（13）个投影快捷方式引入的额外参数

34层普通网仍然能够提高具有竞争力的精度

基准架构与34层普通网络相同，在每对 3×3 filters 上添加一个快捷方式连接。

在第一个比较中（右图 2 和图 4），我们对所有快捷键使用标识映射，对增加维度使用零填充（选项 A）。因此，与普通对应物相比，它们没有额外的参数。

我们推测，深平原网可能具有指数级的低收敛率，这会影响训练误差的减少。这种优化差异的原因将在未来进行研究。 我们已经尝试了更多的训练迭代（3×），并且仍然观察到退化问题，这表明仅仅使用更多的迭代无法解决这个问题。

但是，A/B/C之间的微小差异表明，投影快捷方式对于解决降解问题并不重要。

![image-20220818090233314](https://gitee.com/shuangshuang853/picture-bed/raw/master/image-20220818090233314.png)

表 4.ImageNet 验证集上单模型结果的错误率 （%）（测试集上报告除外）。

![image-20220818090244048](https://gitee.com/shuangshuang853/picture-bed/raw/master/image-20220818090244048.png)

![image-20220818090249558](https://gitee.com/shuangshuang853/picture-bed/raw/master/image-20220818090249558.png)

图5 对于ImageNet的一个更深层次的残差函数F。

左图：**ResNet-34**如图3所示的构建块（在56×56特征图上）。

右图：**ResNet-50/101/152**的“瓶颈”积木。

**注意:主分支与shortcut的输出特征矩阵shape必须相同**，主分支输出特征矩阵的高宽深度必须与输入特征矩阵的高宽深度相同，这样才能保证特征矩阵在相同的维度**参数相加**。（GooLeNet是拼接concat）

我们将构建块修改 为 瓶颈 设计 。对于每个残差函数 F，我们使用 3 层而不是 2 层的堆栈。

这三层是 1×1、3×3 和 1×1 卷积，**其中 1×1 层负责减小然后增加（恢复）维度**（降维或升维），使 3×3 层成为输入/输出放置维度较小的瓶颈。图 5 显示了一个示例，其中两种设计具有相似的时间复杂度。

参数对比：

​					3×3×256×256+3×3×256×256=1,179,648
​					1×1×256×64+3×3×64×64+1×1×64×256=69,632

无参数的标识快捷方式对于瓶颈体系结构尤其重要。

如果将图5（右）中的恒等捷径替换为项目离子，则可以证明时间复杂度和模型尺寸加倍，因为该快捷键连接到两个高维端。

因此 ，标识快捷方式可为瓶颈设计提供更有效的模型。

## 4.2 CIFAR-10 与分析

![image-20220818090340180](https://gitee.com/shuangshuang853/picture-bed/raw/master/image-20220818090340180.png)

![image-20220818090345978](https://gitee.com/shuangshuang853/picture-bed/raw/master/image-20220818090345978.png)

网络输入为 32×32 张图像，减去每像素的均值。

第一层是 3×3 卷积。然后，我们在大小分别为{32，16，8}的特征图上使用具有3×3卷积的6 n层的堆栈，每个特征图大小为2 n层。

筛选器的数量分别为 {16，32，64}。

子采样通过步幅为 2 的卷积执行。该网络以全局平均池10 路全连接层和 softmax 结束。

总共有6n + 2堆叠的加权层。

使用快捷方式连接时，它们已连接到3×3层的对（总共 3n 个快捷方式）。在此数据集上，我们在所有情况下都使用身份快捷方式（即选项A）

![image-20220818090359522](https://gitee.com/shuangshuang853/picture-bed/raw/master/image-20220818090359522.png)

表 6.CIFAR-10 测试集上的分类错误。

所有方法都带有数据增强功能。对于 ResNet-110，我们运行它 5 次，并显示“最佳（平均值±std）”，因此 ，我们的残差模型具有与普通模型完全相同的深度、宽度和参数数量。

我们使用权重衰减0.0001和动量0.9，并在[12]和BN [16]中采用权重初始化，但没有用dropout。

这些模型在两个 GPU 上使用 128 的 mini-batch size 进行训练。

我们从学习速率 0.1 开始，在 32k 和 48k 迭代时将其除以 10，并在 64k 迭代时终止训练，这是在 45k/5k 训练/val 拆分的基础上确定的。

我们遵循[24]中的简单数据增强进行训练：每侧填充4个像素，并从填充图像或其堀区翻转中随机抽取32×32裁剪。

对于测试，我们仅评估原始 32×32 图像的单视图。

我们比较 n = {3，5，7，9}，得到 20 层、32 层、44 层和 56 层网络。

我们进一步探索 n = 18，从而形成一个 110 层 ResNet。

在这种情况下，我们发现0.1的初始学习速率略微太大，无法开始收敛 。 因此，我们使用 0.01 来预热训练，直到训练误差低于 80%（约 400 次迭代），然后返回到 0.1 并继续训练。学习计划的其余部分与之前一样。这个110层网络收敛良好（图6，中间）。它比其他深而薄的参数更少

![image-20220818090503023](https://gitee.com/shuangshuang853/picture-bed/raw/master/image-20220818090503023.png)

对于此小型数据集，1202 层网络可能不必要地大 （19.4M）。应用强正则化（如 maxout [9] 或 dropout [13]）以在此数据集上获得最佳结果（[9， 25， 24， 34]）

图 6.关于CIFAR-10的训练。（虚线表示训练错误率，粗体线表示验证错误率）

左：普通网络。plain-110 的误差高于 60%，不显示。

中：ResNets。 

右： 具有 110 层和 1202 层的 ResNets。

我们探索了一个超过1000层的深度模型。我们设置n = 200，导致1202层网络，我如上所述进行训练。我们的方法没有显示优化难度，这个10个3层网络能够实现训练误差<0.1%（图6，右）。它的测试误差仍然相当不错（7.93%，表6）。

但是，在这样一个非常深入的模型上仍然存在悬而未决的问题。这个1202层网络的测试结果比我们的110层网络差，尽管两者都是有类似的训练错误。我们认为这是因为过度拟合。

![image-20220818090528948](https://gitee.com/shuangshuang853/picture-bed/raw/master/image-20220818090528948.png)

图 7 显示了层响应的标准偏差 （std）

图 7.CIFAR10 上图层响应的标准差 （std）。

响应是每个3×3层的输出，在BN之后和非线性之前。

顶部：图层按其原始顺序显示。 底部：响应按降序排列。

对于ResNets，该分析揭示了残差函数的响应强度。

图7显示ResNets的响应通常比普通对应函数小。

这些结果支持我们的基本动机（Sec.3.1），即残差函数通常可能比非残差函数更接近于零。

我们还注意到，更深层次的ResNet具有较小的响应量级，

当有更多的层时，ResNet的单个层倾向于较少地修改信号。

![image-20220818090604020](https://gitee.com/shuangshuang853/picture-bed/raw/master/image-20220818090604020.png)

表 7.使用 Faster R-CNN baseline 在 PASCAL VOC 2007/2012 测试集上进行目标检测 mAP （%）

![image-20220818090613138](https://gitee.com/shuangshuang853/picture-bed/raw/master/image-20220818090613138.png)

表 8.使用 Faster R-CNN baseline 在 COCO 验证集上的目标检测 mAP （%）



# ResNeX

2017

**Aggregated Residual Transformations for Deep Neural Networks**

深度神经网络的聚合残差变换

![image-20220905110740217](https://gitee.com/shuangshuang853/picture-bed/raw/master/picture/20220905110741.png)

## 网络中的亮点

- 更新了block

![image-20220905110921447](https://gitee.com/shuangshuang853/picture-bed/raw/master/picture/20220905110922.png)

## 实验

![image-20220905111151211](https://gitee.com/shuangshuang853/picture-bed/raw/master/picture/20220905111152.png)

在计算量相同的情况下，错误率更低

![image-20220905111700519](https://gitee.com/shuangshuang853/picture-bed/raw/master/picture/20220905111701.png)



## 分组卷积

​	这就相当于对我们输入特征矩阵的每一个channel分配了一个chaanel为1的卷积核进行卷积

![image-20220905112003438](https://gitee.com/shuangshuang853/picture-bed/raw/master/picture/20220905112004.png)



下面的block模块，它们在数学计算上完全等价

![image-20220905112937173](https://gitee.com/shuangshuang853/picture-bed/raw/master/picture/20220905112938.png)





![image-20220905113443500](https://gitee.com/shuangshuang853/picture-bed/raw/master/picture/20220905113444.png)



![image-20220905113705242](https://gitee.com/shuangshuang853/picture-bed/raw/master/picture/20220905113706.png)



**更新block**

![image-20220905114153444](https://gitee.com/shuangshuang853/picture-bed/raw/master/picture/20220905114154.png)



![image-20220905114218980](https://gitee.com/shuangshuang853/picture-bed/raw/master/picture/20220905114219.png)

为什么要选择 32个 group ?

![image-20220905114522664](https://gitee.com/shuangshuang853/picture-bed/raw/master/picture/20220905114523.png)

​	保持运算量的情况下，设定c和d的的个数。

![image-20220905114738913](https://gitee.com/shuangshuang853/picture-bed/raw/master/picture/20220905114739.png)



## 34 层网络



![image-20220905120811313](https://gitee.com/shuangshuang853/picture-bed/raw/master/picture/20220905120812.png)

![image-20220905115253397](https://gitee.com/shuangshuang853/picture-bed/raw/master/picture/20220905120841.png)

我们注意到，只有当块的深度≥为3时，公式才会产生作用。如果块的深度为=2（例如，[14]中的基本块），那么重新公式就会导致一个宽而密集的模块。插图如图4所示。

![image-20220905115326138](https://gitee.com/shuangshuang853/picture-bed/raw/master/picture/20220905115326.png)
